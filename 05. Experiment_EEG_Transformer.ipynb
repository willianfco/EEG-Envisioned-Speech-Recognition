{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willian Oliveira\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "from eeg_transformer import *\n",
    "from train import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import detrend, filtfilt, butter, iirnotch, welch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "# torch.nn is a module that implements varios useful functions and functors to implement flexible and highly\n",
    "# customized neural networks. We will use nn to define neural network modules, different kinds of layers and\n",
    "# diffrent loss functions\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.nn.functional implements a large variety of activation functions and functional forms of different\n",
    "# neural network layers. Here we will use it for activation functions.\n",
    "import torch.nn.functional as f\n",
    "\n",
    "# torch is the Linear Algebra / Neural Networks library\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Setting Global Determinism\n",
    "SEED = 0\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "set_global_determinism(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 14, 1280)\n",
      "(230,)\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "ds = np.load('char_dataset.npz')\n",
    "X = ds['x']\n",
    "Y = ds['y']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling data into 250ms duration\n",
    "def sampling250ms(X, Y):\n",
    "    X_new = np.zeros((36110,32,14))\n",
    "    Y_new = np.zeros((36110,))\n",
    "    npt = 32\n",
    "    stride = 8\n",
    "    ctr = 0\n",
    "    for i in range(0, X.shape[0]):\n",
    "        y = Y[i]\n",
    "        a= X[i,:,:]\n",
    "        a = a.transpose()\n",
    "        val = 0\n",
    "        while val<=(len(a)-npt):\n",
    "            x = a[val:val+npt,:]\n",
    "            X_new[ctr,:,:] = x\n",
    "            Y_new[ctr] = y\n",
    "            val = val+stride\n",
    "            ctr = ctr+1\n",
    "    return X_new, Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, Y_new = sampling250ms(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape:(28888, 32, 14) -> Train Labels: 28888\n",
      "X_test shape:(7222, 32, 14) -> Test Labels: 7222\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, Y_new, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f'''\n",
    "X_train shape:{X_train.shape} -> Train Labels: {y_train.shape[0]}\n",
    "X_test shape:{X_test.shape} -> Test Labels: {y_test.shape[0]}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, y, train=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.train=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_X, train_y, test_X, test_y):\n",
    "    train_set, test_set = dataset(train_X, train_y, True), dataset(test_X, test_y, False)\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_set, \n",
    "        batch_size=1, \n",
    "        num_workers=1,\n",
    "        pin_memory=True, \n",
    "        drop_last=False,\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            test_set, \n",
    "            batch_size=1, \n",
    "            num_workers=1,\n",
    "            pin_memory=True, \n",
    "            drop_last=False,\n",
    "    )\n",
    "    dataloaders = {\n",
    "        'train': data_loader_train,\n",
    "        'test': data_loader_test\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = get_loaders(X_train, y_train, X_test, y_test)\n",
    "dataloader_train = loaders['train']\n",
    "dataloader_test = loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}\n",
    "opt['Transformer-layers'] = 2\n",
    "opt['Model-dimensions'] = 256\n",
    "opt['feedford-size'] = 512\n",
    "opt['headers'] = 8\n",
    "opt['dropout'] = 0.1\n",
    "opt['src_d'] = 14 # input dimension\n",
    "opt['tgt_d'] = 128 # output dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # mean squared error\n",
    "\n",
    "# setup model using hyperparameters defined above\n",
    "model = make_model(opt['src_d'],opt['tgt_d'],opt['Transformer-layers'],opt['Model-dimensions'],opt['feedford-size'],opt['headers'],opt['dropout'])\n",
    "\n",
    "# setup optimization function\n",
    "model_opt = NoamOpt(model_size=opt['Model-dimensions'], factor=1, warmup=400,\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.015, betas=(0.9, 0.98), eps=1e-9))\n",
    "total_epoch = 10\n",
    "train_losses = np.zeros(total_epoch)\n",
    "test_losses = np.zeros(total_epoch)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    train_loss = run_epoch(data_gen(dataloader_train), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    train_losses[epoch]=train_loss\n",
    "\n",
    "    if (epoch+1)%10 == 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': model_opt.optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                    }, 'model_checkpoint/'+str(epoch)+'.pth')            \n",
    "        torch.save(model, 'model_save/model%d.pth'%(epoch)) # save the model\n",
    "\n",
    "    model.eval() # test the model\n",
    "\n",
    "    test_loss = run_epoch(data_gen(dataloader_test), model, \n",
    "            SimpleLossCompute(model.generator, criterion, None))\n",
    "\n",
    "    test_losses[epoch] = test_loss\n",
    "    print('Epoch[{}/{}], train_loss: {:.6f},test_loss: {:.6f}'\n",
    "              .format(epoch+1, total_epoch, train_loss, test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e332309206fa4a216ff1db22cdf25e91b177567cdd7a00de46b695ca9ae15e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
