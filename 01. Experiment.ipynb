{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "set_global_determinism(seed=SEED) # Setting seed for a reproducible code.\n",
    "print(f'Tensorflow Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 14, 1536)\n",
      "(230,)\n"
     ]
    }
   ],
   "source": [
    "# Importing dataset\n",
    "dataset = np.load('char_normalized_dataset.npz')\n",
    "X = dataset['x']\n",
    "Y = dataset['y']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape:(184, 14, 1536) -> Train Labels: 184\n",
      "X_test shape:(46, 14, 1536) -> Test Labels: 46\n"
     ]
    }
   ],
   "source": [
    "# Since this work is trying to create a model that is robust to every user we will be\n",
    "# Splitting the dataset with Scikit-Learn Train-Test split.\n",
    "# Further work can test if diferent splitting techniques enhance performance of the model\n",
    "# e.g split acording to subjects/labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=SEED)\n",
    "\n",
    "print(f'''\n",
    "X_train shape:{X_train.shape} -> Train Labels: {y_train.shape[0]}\n",
    "X_test shape:{X_test.shape} -> Test Labels: {y_test.shape[0]}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train Label distribution'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    19\n",
       "1.0    17\n",
       "2.0    19\n",
       "3.0    19\n",
       "4.0    20\n",
       "5.0    18\n",
       "6.0    18\n",
       "7.0    19\n",
       "8.0    17\n",
       "9.0    18\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test Label distribution'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    4\n",
       "1.0    6\n",
       "2.0    4\n",
       "3.0    4\n",
       "4.0    3\n",
       "5.0    5\n",
       "6.0    5\n",
       "7.0    4\n",
       "8.0    6\n",
       "9.0    5\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veriffing label distribution of train and test samples\n",
    "display('Train Label distribution', pd.DataFrame(y_train, columns=['label']).groupby(['label'])['label'].count())\n",
    "display('Test Label distribution', pd.DataFrame(y_test, columns=['label']).groupby(['label'])['label'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our Transformer from a pre-trained model Transfer-Learn\n",
    "## Based on https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb#scrollTo=JuxDkcvVIoev\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "\n",
    "# TensorFlow models and layers in transformers accept two formats as input:\n",
    "# having all inputs as keyword arguments (like PyTorch models), or\n",
    "# having all inputs as a list, tuple or dict in the first positional argument.\n",
    "\n",
    "ds_train_TL = list(zip(X_train, y_train))\n",
    "ds_test_TL = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a pre-trained model from Tensorflow Hub\n",
    "\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Create a preprocess layer\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " EEG (InputLayer)               [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " Preprocessing (KerasLayer)     {'input_type_ids':   0           ['EEG[0][0]']                    \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'sequence_output':  177853441   ['Preprocessing[0][0]',          \n",
      "                                 (None, 128, 768),                'Preprocessing[0][1]',          \n",
      "                                 'pooled_output': (               'Preprocessing[0][2]']          \n",
      "                                None, 768),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['BERT_encoder[0][13]']          \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 10)           7690        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 177,861,131\n",
      "Trainable params: 177,861,130\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building our classifier\n",
    "\n",
    "def build_classifier_model():\n",
    "  EEG_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='EEG')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='Preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(EEG_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(10, activation='softmax', name='classifier')(net)\n",
    "  return tf.keras.Model(EEG_input, net)\n",
    "\n",
    "classifier_model = build_classifier_model()\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "steps_per_epoch = len(X_train)\n",
    "num_train_steps = steps_per_epoch * EPOCHS\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with BERT_Multi_Cased_L-12_H-768_A-12\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='EEG'), name='EEG', description=\"created by layer 'EEG'\"), but it was called on an input with incompatible shape (None, 14, 1536).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='EEG'), name='EEG', description=\"created by layer 'EEG'\"), but it was called on an input with incompatible shape (None, 14, 1536).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py\", line 74, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, ('result', 'training'), 1)\n    File \"C:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py\", line 72, in else_body_3\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope))), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope)))), None, fscope)\n    File \"C:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py\", line 72, in <lambda>\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope))), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope)))), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"Preprocessing\" \"                 f\"(type KerasLayer).\n    \n    in user code:\n    \n        File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 237, in call  *\n            result = smart_cond.smart_cond(training,\n    \n        ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n          Positional arguments (3 total):\n            * <tf.Tensor 'inputs:0' shape=(None, 14, 1536) dtype=string>\n            * False\n            * None\n          Keyword arguments: {}\n        \n         Expected these arguments to match one of the following 4 option(s):\n        \n        Option 1:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * True\n            * None\n          Keyword arguments: {}\n        \n        Option 2:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 3:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 4:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * True\n            * None\n          Keyword arguments: {}\n    \n    \n    Call arguments received by layer \"Preprocessing\" \"                 f\"(type KerasLayer):\n      • inputs=tf.Tensor(shape=(None, 14, 1536), dtype=string)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining model with BERT_Multi_Cased_L-12_H-768_A-12\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m classifier_model\u001b[39m.\u001b[39;49mfit(x \u001b[39m=\u001b[39;49m X_train,\n\u001b[0;32m      3\u001b[0m                                y \u001b[39m=\u001b[39;49m y_train,\n\u001b[0;32m      4\u001b[0m                                validation_data \u001b[39m=\u001b[39;49m (X_test, y_test),\n\u001b[0;32m      5\u001b[0m                                epochs\u001b[39m=\u001b[39;49m EPOCHS)\n",
      "File \u001b[1;32mc:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_file824uks7y.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py:74\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     72\u001b[0m     result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope))), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope)))), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     73\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_6\u001b[39m():\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m (result,)\n",
      "File \u001b[1;32mC:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(smart_cond)\u001b[39m.\u001b[39;49msmart_cond, (ag__\u001b[39m.\u001b[39;49mld(training), ag__\u001b[39m.\u001b[39;49mautograph_artifact((\u001b[39mlambda\u001b[39;49;00m : ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope))), ag__\u001b[39m.\u001b[39;49mautograph_artifact((\u001b[39mlambda\u001b[39;49;00m : ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), fscope)))), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "File \u001b[1;32mC:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope))), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope)))), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py\", line 74, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, ('result', 'training'), 1)\n    File \"C:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py\", line 72, in else_body_3\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope))), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope)))), None, fscope)\n    File \"C:\\Users\\WILLIA~1\\AppData\\Local\\Temp\\__autograph_generated_filen4cnfuee.py\", line 72, in <lambda>\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope))), ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope)))), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"Preprocessing\" \"                 f\"(type KerasLayer).\n    \n    in user code:\n    \n        File \"c:\\Users\\Willian Oliveira\\anaconda3\\envs\\tf_py\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 237, in call  *\n            result = smart_cond.smart_cond(training,\n    \n        ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n          Positional arguments (3 total):\n            * <tf.Tensor 'inputs:0' shape=(None, 14, 1536) dtype=string>\n            * False\n            * None\n          Keyword arguments: {}\n        \n         Expected these arguments to match one of the following 4 option(s):\n        \n        Option 1:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * True\n            * None\n          Keyword arguments: {}\n        \n        Option 2:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 3:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 4:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * True\n            * None\n          Keyword arguments: {}\n    \n    \n    Call arguments received by layer \"Preprocessing\" \"                 f\"(type KerasLayer):\n      • inputs=tf.Tensor(shape=(None, 14, 1536), dtype=string)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with BERT_Multi_Cased_L-12_H-768_A-12')\n",
    "history = classifier_model.fit(x = X_train,\n",
    "                               y = y_train,\n",
    "                               validation_data = (X_test, y_test),\n",
    "                               epochs= EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_TL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our Transformer from Scratch\n",
    "## Based on https://github.com/Kyubyong/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd574941279fb6eb59fbc8ec4ea27572da296acbca746f1b5136a7c1b4e2e904"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
